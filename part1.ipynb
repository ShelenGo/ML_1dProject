{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estuvimos O\n",
      "hace O\n",
      "poco O\n",
      "mi O\n",
      "pareja O\n",
      "y O\n",
      "yo O\n",
      "comiendo O\n",
      "y O\n",
      "resultó O\n",
      "todo O\n",
      "muy O\n",
      "bien O\n",
      ", O\n",
      "tanto O\n",
      "la O\n",
      "comida B-positive\n",
      ", O\n",
      "el O\n",
      "vino B-positive\n",
      ", O\n",
      "el O\n",
      "trato B-positive\n",
      ", O\n",
      "la O\n",
      "decoración B-positive\n",
      "… O\n",
      "nos O\n",
      "gustó O\n",
      "todo O\n",
      "mucho O\n",
      ". O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open ('./ES/train', \"r\", encoding=\"utf-8\") as f:\n",
    "    lines_ES = f.read()\n",
    "print(lines_ES[0:248])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Еда B-positive\n",
      "вкусная O\n",
      ", O\n",
      "но O\n",
      "отдельно O\n",
      "хочу O\n",
      "отметить O\n",
      "красивую O\n",
      "сервировку B-positive\n",
      "блюд I-positive\n",
      "; O\n",
      ". O\n",
      "\n",
      "Филадельфию B-positive\n",
      "мне O\n",
      "удалось O\n",
      "только O\n",
      "попробовать O\n",
      ", O\n",
      "сделали O\n",
      "на O\n",
      "отлично O\n",
      ", O\n",
      "хороший O\n",
      "кусок O\n",
      "лосося-филадел\n"
     ]
    }
   ],
   "source": [
    "with open ('./RU/train', \"r\", encoding=\"utf-8\") as f:\n",
    "    lines_RU = f.read()\n",
    "print(lines_RU[0:248])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_and_tags(input_text):\n",
    "    words = []\n",
    "    tags = []\n",
    "    \n",
    "    lines = input_text.strip().split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 2:\n",
    "            word = parts[0]\n",
    "            tag = parts[1]\n",
    "            words.append(word)\n",
    "            tags.append(tag)\n",
    "    \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many unique tags and words in the data\n",
    "def count_unique_tags_and_words(y, x):\n",
    "    unique_tags = set()\n",
    "    unique_words = set()\n",
    "\n",
    "    # Count unique tags and words\n",
    "    for tags, words in zip(y, x):\n",
    "        unique_tags.update(tags)\n",
    "        unique_words.update(words)\n",
    "\n",
    "    num_tags = len(unique_tags)\n",
    "    num_words = len(unique_words)\n",
    "\n",
    "    return num_tags, num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that estimates the emission parameters from the training set using \n",
    "# MLE (maximum likelihood estimation)\n",
    "def estimate_emission_parameters(x, y, num_tags, num_words):\n",
    "    # Initialize emission parameters as a 2D matrix\n",
    "    emission_params = [[0.0 for _ in range(num_words)] for _ in range(num_tags)]\n",
    "    \n",
    "    # Count occurrences of each word given each tag\n",
    "    emission_counts = [[0 for _ in range(num_words)] for _ in range(num_tags)]\n",
    "\n",
    "    # Loop through the training data to count occurrences\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            word = x[i][j]\n",
    "            tag = y[i][j]\n",
    "            emission_counts[tag][word] += 1\n",
    "\n",
    "    # Calculate MLE for emission probabilities\n",
    "    for tag in range(num_tags):\n",
    "        total_count = sum(emission_counts[tag])\n",
    "        if total_count > 0:\n",
    "            for word in range(num_words):\n",
    "                emission_params[tag][word] = emission_counts[tag][word] / total_count\n",
    "\n",
    "    return emission_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X  Y\n",
      "0  Estuvimos  O\n",
      "1       hace  O\n",
      "2       poco  O\n",
      "3         mi  O\n",
      "4     pareja  O\n",
      "17 113\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-892bb8f9f8a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Estimate the emission parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0memission_params_ES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_emission_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tags_ES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words_ES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memission_params_ES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-0b9e6167f145>\u001b[0m in \u001b[0;36mestimate_emission_parameters\u001b[0;34m(x, y, num_tags, num_words)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0memission_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Calculate MLE for emission probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# EU train data\n",
    "# Extract words and tags\n",
    "x_ES, y_ES = extract_words_and_tags(lines_ES)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_ES = pd.DataFrame({'X': x_ES, 'Y': y_ES})\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df_ES.head())\n",
    "\n",
    "# Count how many unique words and tags\n",
    "num_words_ES, num_tags_ES = count_unique_tags_and_words(y_ES, x_ES)\n",
    "print(num_words_ES, num_tags_ES)\n",
    "\n",
    "# Estimate the emission parameters \n",
    "emission_params_ES = estimate_emission_parameters(x_ES, y_ES, num_tags_ES, num_words_ES)\n",
    "print(emission_params_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X           Y\n",
      "0       Еда  B-positive\n",
      "1   вкусная           O\n",
      "2         ,           O\n",
      "3        но           O\n",
      "4  отдельно           O\n"
     ]
    }
   ],
   "source": [
    "# RU train data\n",
    "# Extract words and tags\n",
    "x_RU, y_RU = extract_words_and_tags(lines_RU)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_RU = pd.DataFrame({'X': x_RU, 'Y': y_RU})\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df_RU.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
